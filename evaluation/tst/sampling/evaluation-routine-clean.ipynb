{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5efef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c317777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aca13db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6906a0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ex', 'pect', 'o', 'ĠPatron', 'um']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(tokenizer('Expecto Patronum').input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "412468c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompted_gpt2 import PromptedGPT2Generator\n",
    "from evaluator import Evaluator\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b6c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_seed = 2\n",
    "default_lr = 1e-4\n",
    "default_top_k = 10\n",
    "default_sample_size = 32\n",
    "default_note = ''\n",
    "\n",
    "runs = [\n",
    "#         {'model': 'distilgpt2',\n",
    "#          'machine': 'ec2-82',\n",
    "#          'task': 'pos2neg',\n",
    "#          'data': '500-test',\n",
    "#          'prompt': 'Errorbad WorseException BAD'},\n",
    "        \n",
    "#         {'model': 'distilgpt2',\n",
    "#          'machine': 'petuum-42',\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': '500-test',\n",
    "#          'prompt': ' RatingPros GOOD GOOD GOOD'},\n",
    "        \n",
    "#         {'model': 'distilgpt2',\n",
    "#          'machine': 'ec2-82',\n",
    "#          'task': 'pos2neg',\n",
    "#          'data': '500-train-random',\n",
    "#          'prompt': ' ErrorsError Parameters BADBad'},\n",
    "        \n",
    "#         {'model': 'distilgpt2',\n",
    "#          'machine': 'ec2-82',\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': '500-train-random',\n",
    "#          'prompt': ' Description575 praises Excellent GREAT'},\n",
    "        \n",
    "#         {'model': 'distilgpt2',\n",
    "#          'machine': 'petuum-203',\n",
    "#          'task': 'pos2neg',\n",
    "#          'data': '100-train-first',\n",
    "#          'prompt': ' problemErrorBadExceptionBad'},\n",
    "        \n",
    "#         {'model': 'distilgpt2',\n",
    "#          'machine': 'petuum-203',\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': '100-train-first',\n",
    "#          'prompt': ' mediumExcellentExcellent GREAT GREAT'},\n",
    "        \n",
    "#         {'model': 'gpt2',\n",
    "#          'machine': 'petuum-203',\n",
    "#          'task': 'pos2neg',\n",
    "#          'data': '500-test',\n",
    "#          'prompt': 'Contents ERROR Values ERROR Values'},\n",
    "        \n",
    "#         {'model': 'gpt2',\n",
    "#          'machine': 'petuum-203',\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': '500-test',\n",
    "#          'prompt': ' attributes happiest Parameters Happiness=['},\n",
    "        \n",
    "#         {'model': 'gpt2-medium',\n",
    "#          'machine': 'petuum-42',\n",
    "#          'task': 'pos2neg',\n",
    "#          'data': '500-test',\n",
    "#          'prompt': 'icultyException ConditionException Either'},\n",
    "        \n",
    "#         {'model': 'gpt2-medium',\n",
    "#          'machine': 'ec2-82',\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': '500-test',\n",
    "#          'prompt': ' value MeaningHappy positives (%'},\n",
    "        \n",
    "#         {'model': 'gpt2-large',\n",
    "#          'machine': 'ec2-82',\n",
    "#          'task': 'pos2neg',\n",
    "#          'data': '500-test',\n",
    "#          'prompt': 'Problem objection discrepancyDERR contrasts'},\n",
    "        \n",
    "#         {'model': 'gpt2-large',\n",
    "#          'machine': 'ec2-94',\n",
    "#          'task': 'pos2neg',\n",
    "#          'data': '500-test',\n",
    "#          'prompt': 'AvailabilityDisable Suppose contradictory probabilities'},\n",
    "        \n",
    "#         {'model': 'gpt2-large',\n",
    "#          'machine': 'ec2-82',\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': '500-test',\n",
    "#          'lr': 5e-5,\n",
    "#          'prompt': 'White happiest preferences (− happy'},\n",
    "        \n",
    "#         {'model': 'gpt2-xl',\n",
    "#          'machine': 'ec2-82',\n",
    "#          'task': 'pos2neg',\n",
    "#          'data': '500-test',\n",
    "#          'prompt': 'Error [-either [-Neither'},\n",
    "        \n",
    "#         {'model': 'gpt2',\n",
    "#          'machine': 'baseline',\n",
    "#          'task': 'pos2neg',\n",
    "#          'data': 'none',\n",
    "#          'prompt': ''},\n",
    "        \n",
    "#         {'model': 'gpt2',\n",
    "#          'machine': 'baseline',\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': 'none',\n",
    "#          'prompt': ''},\n",
    "    \n",
    "#         {'model': 'distilgpt2',\n",
    "#          'machine': 'petuum-42',\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': '16-train-first',\n",
    "#          'prompt': ' productExcellent RatingsReviewer GREAT',\n",
    "#          'note': 'input-specific-0'},\n",
    "    \n",
    "#         {'model': 'distilgpt2',\n",
    "#          'machine': 'petuum-42',\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': '16-train-first',\n",
    "#          'prompt': 'photoFavorite happiness LovingThank',\n",
    "#          'note': 'input-specific-1'},\n",
    "    \n",
    "#         {'model': 'distilgpt2',\n",
    "#          'machine': 'petuum-42',\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': '16-train-first',\n",
    "#          'prompt': 'photoExcellent RatingsTopics Ratings',\n",
    "#          'note': 'input-specific-2'},\n",
    "    \n",
    "#         {'model': 'distilgpt2',\n",
    "#          'machine': 'petuum-42',\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': '1k-train-first',\n",
    "#          'prompt': '.[\":[{\"ē happiest GOOD'},\n",
    "    \n",
    "#         {'model': 'distilgpt2',\n",
    "#          'machine': 'ec2-82',\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': '10k-train-first',\n",
    "#          'prompt': ' Austria Unable GREAT praisesPros',\n",
    "#          'note': 'over-trained'},\n",
    "    \n",
    "#         {'model': 'distilgpt2',\n",
    "#          'machine': 'ec2-82',\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': '10k-train-first',\n",
    "#          'prompt': ' PortugExcellent GOOD praisesExcellent'},\n",
    "    \n",
    "#         {'model': 'distilgpt2',\n",
    "#          'machine': 'ec2-82',\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': 'all-train',\n",
    "#          'prompt': ' Greek\":[{\" Excellent greatwhen',\n",
    "#          'note': 'over-trained'},\n",
    "    \n",
    "#         {'model': 'distilgpt2',\n",
    "#          'machine': 'ec2-82',\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': 'all-train',\n",
    "#          'prompt': 'French\":[{\"Excellent greatGood'},\n",
    "        \n",
    "#         {'model': 'gpt2-xl',\n",
    "#          'machine': 'ec2-82',\n",
    "#          'seed': 3,\n",
    "#          'lr': 5e-5,\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': 'all-train',\n",
    "#          'prompt': 'Favorite positive (% probabilitybetween',\n",
    "#          'note': 'prompt top-128 2'},\n",
    "    \n",
    "#         {'model': 'gpt2-xl',\n",
    "#          'machine': 'ec2-82',\n",
    "#          'seed': 4,\n",
    "#          'lr': 5e-5,\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': 'all-train',\n",
    "#          # 'prompt': ' Difference effects (− comparison (−',\n",
    "#          # 'prompt': ' Difference experiences (− contrasting comparison',\n",
    "#          'prompt': 'Difference possibilities (− contrasting comparison'},\n",
    "    \n",
    "#         {'model': 'gpt2-xl',\n",
    "#          'machine': 'ec2-82',\n",
    "#          'seed': 3,\n",
    "#          'lr': 5e-5,\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': 'all-train',\n",
    "#          'prompt': ' Ratings (− contrasting Relative Happiness',\n",
    "#          'note': 'prompt top-30'},   \n",
    "        \n",
    "#         {'model': 'gpt2-large',\n",
    "#          'machine': 'petuum-203',\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': '500-test',\n",
    "#          'prompt': ' Categories reward ratings (% mode'},\n",
    "    \n",
    "#         {'model': 'gpt2-large',\n",
    "#          'machine': 'ec2-94',\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': '500-test',\n",
    "#          'prompt': 'Goodavorable praise (% happiest'},\n",
    "    \n",
    "#         {'model': 'gpt2-large',\n",
    "#          'machine': 'ec2-94',\n",
    "#          'task': 'neg2pos',\n",
    "#          'lr': 5e-5,\n",
    "#          'data': '500-test',\n",
    "#          'prompt': 'Better favorably positive (% ratings'}\n",
    "    \n",
    "#         {'model': 'gpt2-xl',\n",
    "#          'machine': 'ec2-18',\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': 'all-train',\n",
    "#          'lr': 5e-5,\n",
    "#          'seed': 2,\n",
    "#          'prompt': 'Dutch English excellent Correct (>'},\n",
    "    \n",
    "#         {'model': 'gpt2-xl',\n",
    "#          'machine': 'ec2-34',\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': 'all-train',\n",
    "#          'lr': 5e-5,\n",
    "#          'seed': 3,\n",
    "#          'prompt': 'Parameters Comparison)=( Compare either'},\n",
    "    \n",
    "#         {'model': 'gpt2-xl',\n",
    "#          'machine': 'ec2-82',\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': 'all-train',\n",
    "#          'lr': 5e-5,\n",
    "#          'seed': 4,\n",
    "#          'prompt': ' Difference experiences (− contrasting experiences'},\n",
    "    \n",
    "#         {'model': 'gpt2-xl',\n",
    "#          'machine': 'ec2-18',\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': 'all-train',\n",
    "#          'lr': 5e-5,\n",
    "#          'seed': 2,\n",
    "#          'prompt': 'Dutch English excellent Correct reasonably',\n",
    "#          'note': '7000 steps'},\n",
    "    \n",
    "#         {'model': 'gpt2-xl',\n",
    "#          'machine': 'ec2-34',\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': 'all-train',\n",
    "#          'lr': 5e-5,\n",
    "#          'seed': 3,\n",
    "#          'prompt': 'Parameters comparison Choose comparison Either',\n",
    "#          'note': '8000 steps'},\n",
    "    \n",
    "#         {'model': 'gpt2-xl',\n",
    "#          'machine': 'ec2-82',\n",
    "#          'task': 'neg2pos',\n",
    "#          'data': 'all-train',\n",
    "#          'lr': 5e-5,\n",
    "#          'seed': 4,\n",
    "#          'prompt': ' comparisons (− contrasting comparison (−',\n",
    "#          'note': '8000 steps'},\n",
    "    \n",
    "        {'model': 'gpt2-xl',\n",
    "         'machine': 'ec2-82',\n",
    "         'task': 'pos2neg',\n",
    "         'data': 'all-train',\n",
    "         'seed': 2,\n",
    "         'prompt': 'Fixed (− contrasts (− contrasts'},\n",
    "    \n",
    "        {'model': 'gpt2-xl',\n",
    "         'machine': 'ec2-228',\n",
    "         'task': 'pos2neg',\n",
    "         'data': 'all-train',\n",
    "         'seed': 3,\n",
    "         'prompt': 'Fixed RemovedChanged Prevent outcomes'},\n",
    "    \n",
    "        {'model': 'gpt2-large',\n",
    "         'machine': 'ec2-94',\n",
    "         'task': 'pos2neg',\n",
    "         'data': 'all-train',\n",
    "         'seed': 3,\n",
    "         'prompt': 'Initialized complain Errors (> opposite'},\n",
    "    \n",
    "        {'model': 'gpt2-medium',\n",
    "         'machine': 'ec2-239',\n",
    "         'task': 'pos2neg',\n",
    "         'data': 'all-train',\n",
    "         'seed': 2,\n",
    "         'prompt': 'Enabled distinguishes {: forbid perfect'},\n",
    "    \n",
    "        {'model': 'gpt2-medium',\n",
    "         'machine': 'ec2-239',\n",
    "         'task': 'pos2neg',\n",
    "         'data': 'all-train',\n",
    "         'seed': 3,\n",
    "         'prompt': 'Damage exceptionFailure Meaning Meaning'},\n",
    "    \n",
    "       ]\n",
    "        \n",
    "new_runs = []\n",
    "for r in runs: \n",
    "    if 'seed' not in r: r['seed'] = default_seed\n",
    "    if 'lr' not in r: r['lr'] = default_lr\n",
    "    if 'top_k' not in r: r['top_k'] = default_top_k\n",
    "    if 'sample_size' not in r: r['sample_size'] = default_sample_size\n",
    "    if 'note' not in r: r['note'] = default_note\n",
    "    new_runs.append(r)\n",
    "runs = new_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de41fe24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0396ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_outputs(run, \n",
    "                     device=None, \n",
    "                     reward_device=None, \n",
    "                     generator_device=None,\n",
    "                     evaluator_device=None,\n",
    "                     raw_save_path='./raw',\n",
    "                     summary_save_path='./summary'): \n",
    "    if device is not None: \n",
    "        reward_device=device\n",
    "        generator_device=device\n",
    "        evaluator_device=device\n",
    "        \n",
    "    model = run['model']\n",
    "    task = run['task']\n",
    "    sample_size = run['sample_size']\n",
    "    top_k = run['top_k']\n",
    "    \n",
    "    dummy_prompts = {'pos2neg': '', 'neg2pos': ''}\n",
    "    generator = PromptedGPT2Generator(model, \n",
    "                                      dummy_prompts,\n",
    "                                      reward_device=reward_device,\n",
    "                                      generator_device=generator_device)\n",
    "    evaluator = Evaluator(evaluator_device)\n",
    "    \n",
    "    start = time.time()\n",
    "    output_list = generator.sample_generate(task, \n",
    "                                            sample_size, \n",
    "                                            top_k=top_k, \n",
    "                                            top_p=None, \n",
    "                                            single_prompt=run['prompt'])\n",
    "    time_elapsed = time.time() - start\n",
    "    del generator\n",
    "    \n",
    "    summary, output_df = evaluator.evaluate_output(task, \n",
    "                                                   output_list)\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d_%H:%M:%S')\n",
    "    del evaluator\n",
    "    \n",
    "    summary.update({'model': model,\n",
    "                    'task': task,\n",
    "                    'sample_size': sample_size,\n",
    "                    'top_k': top_k,\n",
    "                    'lr': run['lr'],\n",
    "                    'seed': run['seed'],\n",
    "                    'machine': run['machine'],\n",
    "                    'data': run['data'],\n",
    "                    'prompt': run['prompt'],\n",
    "                    'time_elapsed': round(time_elapsed, 2),\n",
    "                    'timestamp': timestamp,\n",
    "                    'note': run['note']})\n",
    "    print(summary)\n",
    "    \n",
    "    output_name = f\"{task}_{model}_{run['data']}_{run['machine']}_{timestamp}\"\n",
    "    json.dump(summary, open(os.path.join(summary_save_path, output_name + '.json'), 'w'))\n",
    "    output_df.to_csv(os.path.join(raw_save_path, output_name + '.csv'), index=False)\n",
    "    \n",
    "    return summary, output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d990147e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  2%|▏         | 10/500 [00:13<11:06,  1.36s/it]/opt/conda/envs/sql-203/lib/python3.8/site-packages/transformers/pipelines/base.py:997: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 500/500 [11:01<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing with reference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 5180.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:03<00:00, 133.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing perplexity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 12426.98it/s]\n",
      "100%|██████████| 500/500 [00:04<00:00, 104.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sum_reward': 89.78, 'recon': 80.8, 'self_bleu': 53.62, 'ref_bleu': 28.17, 'style_acc': 95.6, 'ppl': 32.66, 'model': 'gpt2-xl', 'task': 'pos2neg', 'sample_size': 32, 'top_k': 10, 'lr': 0.0001, 'seed': 2, 'machine': 'ec2-82', 'data': 'all-train', 'prompt': 'Fixed (− contrasts (− contrasts', 'time_elapsed': 661.86, 'timestamp': '2022-05-09_14:01:45', 'note': ''}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  2%|▏         | 10/500 [00:13<11:06,  1.36s/it]/opt/conda/envs/sql-203/lib/python3.8/site-packages/transformers/pipelines/base.py:997: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 500/500 [11:02<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing with reference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 5100.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:03<00:00, 134.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing perplexity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 12450.00it/s]\n",
      "100%|██████████| 500/500 [00:04<00:00, 104.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sum_reward': 87.26, 'recon': 75.95, 'self_bleu': 47.43, 'ref_bleu': 26.11, 'style_acc': 95.0, 'ppl': 33.43, 'model': 'gpt2-xl', 'task': 'pos2neg', 'sample_size': 32, 'top_k': 10, 'lr': 0.0001, 'seed': 3, 'machine': 'ec2-228', 'data': 'all-train', 'prompt': 'Fixed RemovedChanged Prevent outcomes', 'time_elapsed': 662.79, 'timestamp': '2022-05-09_14:13:16', 'note': ''}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  2%|▏         | 10/500 [00:10<08:39,  1.06s/it]/opt/conda/envs/sql-203/lib/python3.8/site-packages/transformers/pipelines/base.py:997: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 500/500 [08:44<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing with reference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 5093.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:03<00:00, 134.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing perplexity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 12554.94it/s]\n",
      "100%|██████████| 500/500 [00:04<00:00, 104.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sum_reward': 87.8, 'recon': 77.19, 'self_bleu': 49.36, 'ref_bleu': 26.26, 'style_acc': 96.2, 'ppl': 33.62, 'model': 'gpt2-large', 'task': 'pos2neg', 'sample_size': 32, 'top_k': 10, 'lr': 0.0001, 'seed': 3, 'machine': 'ec2-94', 'data': 'all-train', 'prompt': 'Initialized complain Errors (> opposite', 'time_elapsed': 524.56, 'timestamp': '2022-05-09_14:22:23', 'note': ''}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  2%|▏         | 10/500 [00:08<06:53,  1.18it/s]/opt/conda/envs/sql-203/lib/python3.8/site-packages/transformers/pipelines/base.py:997: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 500/500 [06:40<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing with reference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 5223.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:03<00:00, 133.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing perplexity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 12913.26it/s]\n",
      "100%|██████████| 500/500 [00:04<00:00, 103.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sum_reward': 84.54, 'recon': 70.09, 'self_bleu': 38.19, 'ref_bleu': 21.09, 'style_acc': 96.4, 'ppl': 35.12, 'model': 'gpt2-medium', 'task': 'pos2neg', 'sample_size': 32, 'top_k': 10, 'lr': 0.0001, 'seed': 2, 'machine': 'ec2-239', 'data': 'all-train', 'prompt': 'Enabled distinguishes {: forbid perfect', 'time_elapsed': 400.72, 'timestamp': '2022-05-09_14:29:22', 'note': ''}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  2%|▏         | 10/500 [00:08<06:43,  1.21it/s]/opt/conda/envs/sql-203/lib/python3.8/site-packages/transformers/pipelines/base.py:997: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 500/500 [06:40<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing with reference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 5235.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:03<00:00, 133.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing perplexity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 12854.45it/s]\n",
      "100%|██████████| 500/500 [00:04<00:00, 103.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sum_reward': 86.15, 'recon': 73.31, 'self_bleu': 42.93, 'ref_bleu': 23.44, 'style_acc': 95.8, 'ppl': 33.2, 'model': 'gpt2-medium', 'task': 'pos2neg', 'sample_size': 32, 'top_k': 10, 'lr': 0.0001, 'seed': 3, 'machine': 'ec2-239', 'data': 'all-train', 'prompt': 'Damage exceptionFailure Meaning Meaning', 'time_elapsed': 400.69, 'timestamp': '2022-05-09_14:36:21', 'note': ''}\n"
     ]
    }
   ],
   "source": [
    "summaries, output_dfs = [], []\n",
    "for _ in range(1): \n",
    "    for r in runs: \n",
    "        summary, output_df = generate_outputs(r, \n",
    "                                              reward_device=2, \n",
    "                                              generator_device=2, \n",
    "                                              evaluator_device=2)\n",
    "        summaries.append(summary)\n",
    "        output_dfs.append(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3274fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33dcd09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3134f4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcca529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "373ad82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "10it [00:04,  2.18it/s]/opt/conda/envs/sql-203/lib/python3.8/site-packages/transformers/pipelines/base.py:997: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "500it [03:48,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing with reference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 5388.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:03<00:00, 128.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing perplexity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 13777.84it/s]\n",
      "100%|██████████| 500/500 [00:04<00:00, 100.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sum_reward': 75.34, 'recon': 52.16, 'self_bleu': 22.89, 'ref_bleu': 14, 'style_acc': 0.99, 'ppl': 34.68, 'model': 'distilgpt2', 'task': 'neg2pos', 'sample_size': 32, 'top_k': 10, 'lr': 0.0001, 'seed': 2, 'machine': 'petuum-42', 'data': '500-test', 'time_elapsed': 228.76, 'timestamp': '2022-04-25_22:24:27', 'note': ''}\n"
     ]
    }
   ],
   "source": [
    "summaries, output_dfs = [], []\n",
    "for r in runs: \n",
    "    summary, output_df = generate_outputs(r, \n",
    "                                          reward_device=3, \n",
    "                                          generator_device=2, \n",
    "                                          evaluator_device=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a649460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [00:13, 38.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "neg2pos_ref_output = []\n",
    "for i, (src, ref) in tqdm(enumerate(zip(generator.sentence_dict['src_neg2pos'],\n",
    "                                        evaluator.sentence_dict['ref_neg2pos']))): \n",
    "    output = generator._select_output([ref],\n",
    "                                       [src], \n",
    "                                       'LABEL_1', \n",
    "                                       sample_id=i)\n",
    "    neg2pos_ref_output.append(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sql-203",
   "language": "python",
   "name": "sql-203"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
