{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bc16988-0335-4340-aa8d-0b9fc691275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import yaml\n",
    "from argparse import Namespace\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForMaskedLM\n",
    ")\n",
    "from tasks.dataset import FewShotDataset\n",
    "from tasks.processors import compute_metrics_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84100c53-a86e-43d7-b706-9a878c27c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55da2a00-b82d-481e-92aa-9380e90fb34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be4aa9a9-cc37-478a-b9c3-7db213ad6e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-large')\n",
    "generator = AutoModelForMaskedLM.from_pretrained('roberta-large').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a546f455-110a-45bb-8c6d-35c982be5b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/config.yaml\", \"r\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "config = config['translation']['classification']\n",
    "config = Namespace(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62ece621-d3c1-4410-a50f-8a373becc0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(data_dir='/home/c2hsieh/soft-Q-learning-for-text-generation/tasks/k-shot/SST-2/16-100', debug_mode=False, demo_filter=False, demo_filter_model=None, demo_filter_rate=0.5, first_sent_limit=None, gpt3_in_context_head=False, gpt3_in_context_num=32, gpt3_in_context_tail=False, mapping=\"{'0':'terrible','1':'great'}\", max_seq_length=512, num_sample=16, other_sent_limit=None, overwrite_cache=None, prompt=True, task_name='sst-2', template='*cls**sent_0*_It_was*mask*.*sep+*', template_list=None, use_demo=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_name = \"SST-2\"\n",
    "config.task_name = task_name.lower()\n",
    "config.template = \"*cls**sent_0*_It_was*mask*.*sep+*\"\n",
    "config.mapping = \"{\\'0\\':\\'terrible\\',\\'1\\':\\'great\\'}\"\n",
    "config.data_dir = f\"/home/c2hsieh/soft-Q-learning-for-text-generation/tasks/k-shot/{task_name}/16-{seed}\"\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e4162dc8-68c3-4d0b-aea6-e94b646b0323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(data_dir='/home/c2hsieh/soft-Q-learning-for-text-generation/tasks/k-shot/sst-5/16-87', debug_mode=False, demo_filter=False, demo_filter_model=None, demo_filter_rate=0.5, first_sent_limit=None, gpt3_in_context_head=False, gpt3_in_context_num=32, gpt3_in_context_tail=False, mapping=\"{0:'terrible',1:'bad',2:'okay',3:'good',4:'great'}\", max_seq_length=512, num_sample=16, other_sent_limit=None, overwrite_cache=None, prompt=True, task_name='sst-5', template='*cls**sent_0*_It_was*mask*.*sep+*', template_list=None, use_demo=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_name = \"sst-5\"\n",
    "config.task_name = task_name.lower()\n",
    "config.template = \"*cls**sent_0*_It_was*mask*.*sep+*\"\n",
    "config.mapping = \"{0:\\'terrible\\',1:\\'bad\\',2:\\'okay\\',3:\\'good\\',4:\\'great\\'}\"\n",
    "config.data_dir = f\"/home/c2hsieh/soft-Q-learning-for-text-generation/tasks/k-shot/{task_name}/16-{seed}\"\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ee574da-c62e-406e-85f2-d609f037f03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(data_dir='/home/c2hsieh/soft-Q-learning-for-text-generation/tasks/k-shot/MRPC/16-100', debug_mode=False, demo_filter=False, demo_filter_model=None, demo_filter_rate=0.5, first_sent_limit=None, gpt3_in_context_head=False, gpt3_in_context_num=32, gpt3_in_context_tail=False, mapping=\"{'0':'No','1':'Yes'}\", max_seq_length=512, num_sample=16, other_sent_limit=None, overwrite_cache=None, prompt=True, task_name='mrpc', template='*cls**sent_0**mask*,*+sentl_1**sep+*', template_list=None, use_demo=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_name = \"MRPC\"\n",
    "config.task_name = task_name.lower()\n",
    "config.template = \"*cls**sent_0**mask*,*+sentl_1**sep+*\"\n",
    "config.mapping = \"{'0':'No','1':'Yes'}\"\n",
    "config.data_dir = f\"/home/c2hsieh/soft-Q-learning-for-text-generation/tasks/k-shot/{task_name}/16-{seed}\"\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "271355ae-2d86-4591-8b7e-dcc67055dde9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'absolutely unequivocallyliterally unequivocally unequivocally'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_100 = 'absolutely seriously Absolutely Simply Simply'\n",
    "prompt_87 = 'absolutely unequivocallyliterally unequivocally unequivocally'\n",
    "prompt_string = prompt_87\n",
    "# prompt_string = tokenizer.convert_tokens_to_string(prompt.split())\n",
    "prompt_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c0fa6ca-5d41-4272-ac79-c9efb3bc2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FewShotDataset(config, tokenizer=tokenizer, mode=\"test\")\n",
    "dataset.use_learned_prompt = True\n",
    "dataset.set_learned_prompt([prompt_string])\n",
    "metrics_fn = compute_metrics_mapping[config.task_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a07b413-336e-4061-a535-e5109b50362b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ġterrible', 'Ġbad', 'Ġokay', 'Ġgood', 'Ġgreat']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.convert_ids_to_tokens(i) for i in dataset.get_labels_tok()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9071ffab-0b82-458e-b29d-3c9ef0f2ba2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20c2306d6444c74b82994550a999a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.3900452488687783}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, collate_fn=dataset.collate_fn, num_workers=4, pin_memory=True, batch_size=16, shuffle=False)\n",
    "pred_labels, true_labels = [], []\n",
    "for batch in tqdm(dataloader):\n",
    "    with torch.no_grad():\n",
    "        logits = generator(\n",
    "            input_ids=batch['input_ids'].to(device),\n",
    "            attention_mask=batch['attention_mask'].to(device),\n",
    "        ).logits.cpu()\n",
    "\n",
    "    logits = logits[range(logits.shape[0]), batch['mask_pos'].squeeze()]\n",
    "    pred_labels += logits[:, dataset.get_labels_tok()].argmax(1).tolist()\n",
    "    true_labels += batch['labels'].squeeze().tolist()\n",
    "\n",
    "metrics = metrics_fn(config.task_name, np.array(pred_labels), np.array(true_labels))\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7336833-5068-44d8-8720-033f7e2b389f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdc481b-ecec-4231-b9dd-8db52df8f3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sql",
   "language": "python",
   "name": "sql"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
