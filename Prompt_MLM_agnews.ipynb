{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30b7088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    RobertaModel,\n",
    "    AutoModelForMaskedLM)\n",
    "device = 1\n",
    "generator=AutoModelForMaskedLM.from_pretrained('roberta-large').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ef4ac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbalizer_1 = 'World'#'\\u0120World'#'\\u0120World'#'\\u0120good'#'\\u0120great' #\\u0120wonderful'#'\\u0120wonderful'#'\\u0120positive'\n",
    "verbalizer_2 = 'Sports'#'\\u0120Sports'#'\\u0120Sports' #'\\u0120bad'#'\\u0120terrible'#'\\u0120bad'#'\\u0120bad'#'\\u0120negative'\n",
    "verbalizer_3 = 'Business'#'\\u0120Business'#'\\u0120Business'\n",
    "verbalizer_4 = 'Tech'#'\\u0120Tech'#'\\u0120Tech'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bcd1003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f59bb7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_1 = tokenizer.convert_tokens_to_ids(verbalizer_1)\n",
    "id_2 = tokenizer.convert_tokens_to_ids(verbalizer_2)\n",
    "id_3 = tokenizer.convert_tokens_to_ids(verbalizer_3)\n",
    "id_4 = tokenizer.convert_tokens_to_ids(verbalizer_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1c6967fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def evaluate_acc(formatted_prompt, label):\n",
    "    encoded_input = tokenizer(formatted_prompt, padding='longest', truncation=True, return_tensors='pt', add_special_tokens=True)\n",
    "    #torch.ne(encoded_input.input_ids, tokenizer.pad_token_id).sum(-1) - 2\n",
    "    batch_size = len(formatted_prompt)\n",
    "    seq_len = [1 for _ in range(batch_size)]\n",
    "    with torch.no_grad():\n",
    "        logits = generator(\n",
    "                    input_ids=encoded_input.input_ids.to(device),\n",
    "                    attention_mask=encoded_input.attention_mask.to(device)\n",
    "                    ).logits\n",
    "        #print(logits.shape)\n",
    "        logits = logits[range(batch_size), seq_len]\n",
    "        #print(logits.shape)\n",
    "        logits = logits[:,[id_1, id_2, id_3, id_4]]\n",
    "        output_probs = torch.softmax(logits,dim=-1)\n",
    "        predicted_label = torch.argmax(output_probs, dim=-1)\n",
    "        acc_mat = torch.eq(predicted_label.cpu(), label)\n",
    "        sum_acc = torch.sum(acc_mat)\n",
    "    #label = 0\n",
    "    #for i in range(1,4):\n",
    "    #    if output_probs[i] > max_prob:\n",
    "    #        max_prob = output_probs[i]\n",
    "    #        label = i\n",
    "    return sum_acc\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df186b97",
   "metadata": {},
   "source": [
    "# 1. agnews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b9fd7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (/home/jianyu/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    }
   ],
   "source": [
    "# datasets loader\n",
    "from datasets import load_dataset\n",
    "agnews_ = load_dataset(\"ag_news\", split = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c611c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_map(example):\n",
    "    example['text'] = '<mask> News: '+example['text']\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3deca3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jianyu/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-e6a4aa55bdc4f43f.arrow\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "agnews = agnews_.map(prompt_map)\n",
    "test_agnews_dataloader = torch.utils.data.DataLoader(agnews, batch_size=128, num_workers=5, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4477ab7",
   "metadata": {},
   "source": [
    "# next(iter(test_agnews_dataloader))['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be18824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:25,  1.41it/s]"
     ]
    }
   ],
   "source": [
    "count = 0# bias, variance also matters a lot. -> more examples\n",
    "import tqdm # Center staff: 77.88%\n",
    "for i, batch in tqdm.tqdm(enumerate(iter(test_agnews_dataloader))):# \n",
    "    #if i == 0:\n",
    "    #    continue # �� cabin, 0.8125 | �� Armor, 0.843 | '��py,0.84\n",
    "    text = batch['text']#element.strip('\\n').split('\\t')[0] # ��inventoryQuantity, 0.82->\n",
    "    label = batch['label']#element.strip('\\n').split('\\t')[-1] # �� guiActiveUnfocused, 0.84375 # Beta版 , Preview版, Rocket版 DragonMagazine版, Preview王, Ultra版, Revolution王\n",
    "    count += evaluate_acc(text, label)\n",
    "    #print(label) # MS Why: improved 70.55%->traiing, ellation Reaction->75.73% (comparable-90 on dev), monsming->0.7048\n",
    "    #if acc == int(label): # 0.7563780568407138, Guide Guide, -> 85/90+ 16-shot\n",
    "    #    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5732f5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "count/len(agnews_['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a42c22e",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c2e31c",
   "metadata": {},
   "source": [
    "agnews_2 = []\n",
    "agnews_3 = []\n",
    "agnews_0 = []\n",
    "agnews_1 = []\n",
    "for i, text in enumerate(agnews_['train']['text']):\n",
    "    if len(agnews_0) == 48 and len(agnews_1) == 48 and len(agnews_2) == 48 and len(agnews_3) == 48:\n",
    "            break\n",
    "    label = agnews_['train']['label'][i]\n",
    "    if label == 0:\n",
    "        if len(agnews_0) == 48:\n",
    "            continue\n",
    "        agnews_0.append(text)\n",
    "    elif label == 1:\n",
    "        if len(agnews_1) == 48:\n",
    "            continue\n",
    "        agnews_1.append(text)\n",
    "    elif label == 2:\n",
    "        if len(agnews_2) == 48:\n",
    "            continue\n",
    "        agnews_2.append(text)\n",
    "    elif label == 3:\n",
    "        if len(agnews_3) == 48:\n",
    "            continue\n",
    "        agnews_3.append(text)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb9b364",
   "metadata": {},
   "source": [
    "with open('/data/jianyu/test/soft-Q-learning-for-text-generation/24-train.tsv', 'w') as f:\n",
    "    f.write('text\\tlabel\\n')\n",
    "    for text in agnews_0[:24]:\n",
    "        f.write(text+'\\t0\\n')\n",
    "    for text in agnews_1[:24]:\n",
    "        f.write(text+'\\t1\\n')\n",
    "    for text in agnews_2[:24]:\n",
    "        f.write(text+'\\t2\\n')\n",
    "    for text in agnews_3[:24]:\n",
    "        f.write(text+'\\t3\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6bb3fa",
   "metadata": {},
   "source": [
    "with open('/data/jianyu/test/soft-Q-learning-for-text-generation/24-dev.tsv', 'w') as f:\n",
    "    f.write('text\\tlabel\\n')\n",
    "    for text in agnews_0[24:]:\n",
    "        f.write(text+'\\t0\\n')\n",
    "    for text in agnews_1[24:]:\n",
    "        f.write(text+'\\t1\\n')\n",
    "    for text in agnews_2[24:]:\n",
    "        f.write(text+'\\t2\\n')\n",
    "    for text in agnews_3[24:]:\n",
    "        f.write(text+'\\t3\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
