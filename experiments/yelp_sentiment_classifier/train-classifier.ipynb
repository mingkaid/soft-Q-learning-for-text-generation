{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "funded-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "novel-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yelp_sentiment(mode): \n",
    "    assert mode in ['train', 'dev', 'test']\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    base_dir = '/jupyter/prompt-generation/soft-Q-learning-for-text-generation/data/yelp-gpt2/raw/'\n",
    "    for label_val in [0, 1]: \n",
    "        filename = f'sentiment.{mode}.{label_val}'\n",
    "        filepath = os.path.join(base_dir, filename)\n",
    "        with open(filepath, 'r') as fr: \n",
    "            new_sentences = [l.strip() for l in fr.readlines()]\n",
    "            new_labels = [label_val for _ in new_sentences]\n",
    "            sentences += new_sentences\n",
    "            labels += new_labels\n",
    "    return sentences, labels            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bibliographic-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, labels_train = read_yelp_sentiment('train')\n",
    "sentences_dev, labels_dev = read_yelp_sentiment('dev')\n",
    "sentences_test, labels_test = read_yelp_sentiment('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "plain-throat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "444101"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "honest-print",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63483"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "emerging-professional",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126670"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "respective-basis",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train_test, labels_train_test = sentences_train + sentences_test, labels_train + labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "decent-disabled",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "human-zambia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_encodings = tokenizer(sentences_train, truncation=True, padding=True)\n",
    "train_test_encodings = tokenizer(sentences_train_test, truncation=True, padding=True)\n",
    "dev_encodings = tokenizer(sentences_dev, truncation=True, padding=True)\n",
    "# test_encodings = tokenizer(sentences_test, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "according-longer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YelpDataset(Dataset): \n",
    "    def __init__(self, encodings, labels): \n",
    "        # assert len(sentences) == len(labels)\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self): \n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "level-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = YelpDataset(train_encodings, labels_train)\n",
    "train_test_dataset = YelpDataset(train_test_encodings, labels_train_test)\n",
    "dev_dataset = YelpDataset(dev_encodings, labels_dev)\n",
    "# test_dataset = YelpDataset(test_encodings, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-consortium",
   "metadata": {},
   "source": [
    "# Train and experiment with some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "round-antenna",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "labeled-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_name = \"accuracy\"\n",
    "batch_size = 64\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"./results-bert-base-train-test\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    gradient_accumulation_steps=1,\n",
    "#     logging_dir='/jupyter/runs/20210728-1144-yelp-classifier',\n",
    "    logging_dir='/jupyter/runs/20211201-1652-yelp-classifier',\n",
    "    logging_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "employed-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "shaped-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=args,                  # training arguments, defined above\n",
    "    compute_metrics=compute_metrics,\n",
    "#     train_dataset=train_dataset,         # training dataset\n",
    "#     train_dataset=test_dataset, \n",
    "    train_dataset=train_test_dataset, \n",
    "    eval_dataset=dev_dataset             # evaluation dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "through-joining",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 570771\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22300\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmingkaid\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">./results-bert-base-train-test</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mingkaid/huggingface\" target=\"_blank\">https://wandb.ai/mingkaid/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mingkaid/huggingface/runs/34fm58lx\" target=\"_blank\">https://wandb.ai/mingkaid/huggingface/runs/34fm58lx</a><br/>\n",
       "                Run data is saved locally in <code>/jupyter/prompt-generation/soft-Q-learning-for-text-generation/experiments/yelp_sentiment_classifier/wandb/run-20211201_215339-34fm58lx</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22300' max='22300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22300/22300 2:22:54, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.081400</td>\n",
       "      <td>0.050136</td>\n",
       "      <td>0.982515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.055800</td>\n",
       "      <td>0.048613</td>\n",
       "      <td>0.984563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.053015</td>\n",
       "      <td>0.984453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.063666</td>\n",
       "      <td>0.984090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.072155</td>\n",
       "      <td>0.984279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 63483\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to ./results-bert-base-train-test/checkpoint-4460\n",
      "Configuration saved in ./results-bert-base-train-test/checkpoint-4460/config.json\n",
      "Model weights saved in ./results-bert-base-train-test/checkpoint-4460/pytorch_model.bin\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 63483\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to ./results-bert-base-train-test/checkpoint-8920\n",
      "Configuration saved in ./results-bert-base-train-test/checkpoint-8920/config.json\n",
      "Model weights saved in ./results-bert-base-train-test/checkpoint-8920/pytorch_model.bin\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 63483\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to ./results-bert-base-train-test/checkpoint-13380\n",
      "Configuration saved in ./results-bert-base-train-test/checkpoint-13380/config.json\n",
      "Model weights saved in ./results-bert-base-train-test/checkpoint-13380/pytorch_model.bin\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 63483\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to ./results-bert-base-train-test/checkpoint-17840\n",
      "Configuration saved in ./results-bert-base-train-test/checkpoint-17840/config.json\n",
      "Model weights saved in ./results-bert-base-train-test/checkpoint-17840/pytorch_model.bin\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 63483\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to ./results-bert-base-train-test/checkpoint-22300\n",
      "Configuration saved in ./results-bert-base-train-test/checkpoint-22300/config.json\n",
      "Model weights saved in ./results-bert-base-train-test/checkpoint-22300/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=22300, training_loss=0.03429967642636477, metrics={'train_runtime': 8585.6371, 'train_samples_per_second': 332.399, 'train_steps_per_second': 2.597, 'total_flos': 6.15956906983698e+16, 'train_loss': 0.03429967642636477, 'epoch': 5.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-boston",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-statement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-coverage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-showcase",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-orchestra",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "interesting-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base', use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "undefined-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(sentences_train, truncation=True, padding=True)\n",
    "dev_encodings = tokenizer(sentences_dev, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(sentences_test, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "strong-miami",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YelpDataset(Dataset): \n",
    "    def __init__(self, encodings, labels): \n",
    "        # assert len(sentences) == len(labels)\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self): \n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "central-intranet",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = YelpDataset(train_encodings, labels_train)\n",
    "dev_dataset = YelpDataset(dev_encodings, labels_dev)\n",
    "test_dataset = YelpDataset(test_encodings, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "intense-pittsburgh",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "heated-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_name = \"accuracy\"\n",
    "batch_size = 64\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"./20210728-1155-results\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    gradient_accumulation_steps=1,\n",
    "    logging_dir='/jupyter/runs/20210728-1155-yelp-classifier',\n",
    "    logging_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "finished-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=args,                  # training arguments, defined above\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=dev_dataset             # evaluation dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "textile-concern",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='17350' max='17350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17350/17350 1:42:01, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.059425</td>\n",
       "      <td>0.980357</td>\n",
       "      <td>53.294400</td>\n",
       "      <td>1191.176000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.045300</td>\n",
       "      <td>0.062406</td>\n",
       "      <td>0.981318</td>\n",
       "      <td>54.332500</td>\n",
       "      <td>1168.417000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.060153</td>\n",
       "      <td>0.983318</td>\n",
       "      <td>52.697400</td>\n",
       "      <td>1204.671000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.062301</td>\n",
       "      <td>0.983492</td>\n",
       "      <td>52.719800</td>\n",
       "      <td>1204.158000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.071162</td>\n",
       "      <td>0.983334</td>\n",
       "      <td>52.749200</td>\n",
       "      <td>1203.488000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=17350, training_loss=0.04341075189969897, metrics={'train_runtime': 6121.7333, 'train_samples_per_second': 2.834, 'total_flos': 4.31776276184526e+16, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': -154415104, 'init_mem_gpu_alloc_delta': 499849216, 'init_mem_cpu_peaked_delta': 154415104, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 4583424, 'train_mem_gpu_alloc_delta': 1501474304, 'train_mem_cpu_peaked_delta': 309334016, 'train_mem_gpu_peaked_delta': 1177982464})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-paste",
   "metadata": {},
   "source": [
    "# Try the best trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dress-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"./results-bert-base/checkpoint-10410/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "under-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "args = TrainingArguments(\n",
    "    \"./results\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    gradient_accumulation_steps=1,\n",
    "    logging_dir='/jupyter/runs/20210728-1144-yelp-classifier',\n",
    "    logging_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "handmade-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "vital-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=args,                  # training arguments, defined above\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=dev_dataset             # evaluation dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "exceptional-framing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1486' max='496' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [496/496 04:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmingkaid\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">./results</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mingkaid/huggingface\" target=\"_blank\">https://wandb.ai/mingkaid/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mingkaid/huggingface/runs/3jqmk0m3\" target=\"_blank\">https://wandb.ai/mingkaid/huggingface/runs/3jqmk0m3</a><br/>\n",
       "                Run data is saved locally in <code>/workspace/soft-Q-learning-for-text-generation/experiments/yelp_sentiment_classifier/wandb/run-20210728_211010-3jqmk0m3</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.055661026388406754,\n",
       " 'eval_accuracy': 0.9839012018965707,\n",
       " 'eval_runtime': 55.0991,\n",
       " 'eval_samples_per_second': 1152.16,\n",
       " 'init_mem_cpu_alloc_delta': 1674260480,\n",
       " 'init_mem_gpu_alloc_delta': 439072256,\n",
       " 'init_mem_cpu_peaked_delta': 93827072,\n",
       " 'init_mem_gpu_peaked_delta': 0,\n",
       " 'eval_mem_cpu_alloc_delta': 434532352,\n",
       " 'eval_mem_gpu_alloc_delta': 0,\n",
       " 'eval_mem_cpu_peaked_delta': 385024,\n",
       " 'eval_mem_gpu_peaked_delta': 81342464}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "vanilla-credits",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.06177423521876335,\n",
       " 'eval_accuracy': 0.9817320596826399,\n",
       " 'eval_runtime': 103.5566,\n",
       " 'eval_samples_per_second': 1223.196,\n",
       " 'eval_mem_cpu_alloc_delta': 1658880,\n",
       " 'eval_mem_gpu_alloc_delta': 0,\n",
       " 'eval_mem_cpu_peaked_delta': 1024000,\n",
       " 'eval_mem_gpu_peaked_delta': 71845888}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-daisy",
   "metadata": {},
   "source": [
    "The test accuracy is 98.17%, which is pretty good. Let's try to make it a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "approximate-disposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "thousand-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline('sentiment-analysis',\n",
    "                      model='./results-bert-base/checkpoint-10410/',\n",
    "                      tokenizer='bert-base-uncased',\n",
    "                      device=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ordinary-planet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9999176263809204},\n",
       " {'label': 'LABEL_0', 'score': 0.9999401569366455},\n",
       " {'label': 'LABEL_1', 'score': 0.9971464276313782},\n",
       " {'label': 'LABEL_0', 'score': 0.9991219639778137},\n",
       " {'label': 'LABEL_0', 'score': 0.9998542666435242}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = classifier([\"Sorry but i do n't get the rave reviews for this place .\",\n",
    "            \"the $ _num_ minimum charge to use a credit card is also annoying .\",\n",
    "            \"they 're quite generous with the shrimp !\",\n",
    "                    \"in my mind there are only two things I can have that my mind cannot control\",\n",
    "                    \"I am not in a position to describe the issues that have occurred in my past. Now it is time\"])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "collected-valentine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "right-stationery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "signal-consequence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9999401569366455}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"the $ _num_ minimum charge to use a credit card is also annoying .\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fleet-arcade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9971464276313782}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"they 're quite generous with the shrimp !\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "integrated-content",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.7880922555923462}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(['Crisse & Rosemary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "first-exemption",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 991/991 [00:56<00:00, 17.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall 0: 0.9759079041063375\n",
      "Precision 0: 0.9835732227582632\n",
      "Recall 1: 0.9891993918104126\n",
      "Precision 1: 0.9841170487442297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "n_correct_0 = 0\n",
    "n_total_0 = 0\n",
    "n_predict_0 = 0\n",
    "\n",
    "n_correct_1 = 0\n",
    "n_total_1 = 0\n",
    "n_predict_1 = 0\n",
    "for i in tqdm(range(len(sentences_dev) // batch_size)): \n",
    "    sentences = sentences_dev[i*batch_size:(i+1)*batch_size]\n",
    "    labels = np.array(labels_dev[i*batch_size:(i+1)*batch_size])\n",
    "    outputs = classifier(sentences, truncation=True)\n",
    "    predictions = np.array([int(o['label'][-1]) for o in outputs])\n",
    "    \n",
    "    is_correct = predictions == labels\n",
    "    is_0 = labels == 0\n",
    "    predict_0 = predictions == 0\n",
    "    n_correct_0 += (is_correct & is_0).sum()\n",
    "    n_predict_0 += predict_0.sum()\n",
    "    n_total_0 += is_0.sum()\n",
    "    n_correct_1 += (is_correct & ~is_0).sum()\n",
    "    n_predict_1 += (~predict_0).sum()\n",
    "    n_total_1 += (~is_0).sum()\n",
    "    \n",
    "print('Recall 0:', n_correct_0 / n_total_0)\n",
    "print('Precision 0:', n_correct_0 / n_predict_0)\n",
    "print('Recall 1:', n_correct_1 / n_total_1)\n",
    "print('Precision 1:', n_correct_1 / n_predict_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "stopped-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dev_dataset, batch_size=64, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cutting-civilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "trying-grounds",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  7929,  2196,  ...,     0,     0,     0],\n",
       "         [  101, 10957,  2154,  ...,     0,     0,     0],\n",
       "         [  101,  1996,  3677,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  2036,  1996,  ...,     0,     0,     0],\n",
       "         [  101,  1045,  2572,  ...,     0,     0,     0],\n",
       "         [  101,  1045,  2052,  ...,     0,     0,     0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'labels': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "catholic-opposition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ok never going back to this place again .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_dev[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
